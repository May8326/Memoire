
@online{filabes_lindexation_2025,
	title = {L’indexation {RAMEAU} assistée par {IA} : retour sur une expérimentation prometteuse},
	url = {https://fil.abes.fr/2025/04/10/lindexation-rameau-assistee-par-ia-retour-sur-une-experimentation-prometteuse/},
	shorttitle = {L’indexation {RAMEAU} assistée par {IA}},
	abstract = {Un service innovant testé par 81 bibliothécaires À l’issue d’une expérimentation conduite entre octobre 2024 et janvier 2025, l’Abes publie le rapport « Indexation  {RAMEAU} assistée par {IA} ». Ce document présente les enseignements tirés de l’évaluation d’un service d’indexation automatique des sujets {RAMEAU}, développé par le Labo et évalué au sein de l’Abes, puis testé par […]},
	titleaddon = {{FIL}'{ABES}},
	author = {{filabes}},
	urldate = {2025-04-11},
	date = {2025-04-10},
	langid = {french},
	keywords = {\_automatisation {IA}, \_exemple, {texNumeriquePatrimoine}},
}

@thesis{gaydon_gaydon_2020,
	location = {Lyon},
	title = {Gaydon, Charlène. Du musée traditionnel au Musée du {XXIe} siècle, la transformation numérique de l’institution : le cas des musées lyonnais.},
	url = {https://www.enssib.fr/bibliotheque-numerique/documents/69395-du-musee-traditionnel-au-musee-du-xxie-siecle-la-transformation-numerique-de-l-institution.pdf},
	pagetotal = {150},
	institution = {Enssib},
	type = {phdthesis},
	author = {Gaydon, Charlène},
	urldate = {2025-05-20},
	date = {2020-03-09},
	keywords = {{texNumeriquePatrimoine}},
}

@article{verhulst_reconstitution_1997,
	title = {Reconstitution et réorganisation de l'inventaire ethnographique au musée d'histoire naturelle de Lille},
	url = {https://dumas.ccsd.cnrs.fr/dumas-01717237},
	abstract = {Durant ce stage, je me suis rendu compte que les possibilités du logiciel Micromusée n'étaient pas pleinement exploitées et qu'un meilleur traitement de l'information ne ferait que renforcer la gestion de la collection ethnographique et celle du Musée d'Histoire Naturelle. Il s'agira ici d'analyser les impératifs du musée et de montrer les utilités et les avantages que le logiciel serait à même d'apporter, une fois la reconstitution et la réorganisation de l'inventaire ethnographique accomplie. Après avoir défini de façon générale la notion d'inventaire, j'aborderai tout d'abord l'utilité de Micromusée dans la gestion interne du musée et de sa collection extra-européenne. Je montrerai quels types d'informations pourront être reçus et apportés par l'utilisateur et quels seront les avantages apportés par le logiciel. Dans un second temps, j'aborderai l'utilité de Micromusée dans la gestion externe du musée et de son fonds ethnographique, c'est à dire dans sa mise en réseau. Qu'est-ce-que cette mise en réseau pourra apporter à ses utilisateurs et au Musée d'Histoire Naturelle et quels en seront les avantages et les difficultés ? Enfin, je me tournerai, en guise de conclusion, vers les difficultés d'une normalisation et tenterai de montrer les problèmes existants.},
	pages = {83},
	author = {Verhulst, David},
	urldate = {2025-05-21},
	date = {1997},
	langid = {french},
	keywords = {\_automatisation {IA}, \_exemple, \_theorie, {texNumeriquePatrimoine}},
}

@article{weaver_herbarium_2023,
	title = {Herbarium specimen label transcription reimagined with large language models: Capabilities, productivity, and risks},
	volume = {110},
	rights = {© 2023 The Authors. American Journal of Botany published by Wiley Periodicals {LLC} on behalf of Botanical Society of America.},
	issn = {1537-2197},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ajb2.16256},
	doi = {10.1002/ajb2.16256},
	shorttitle = {Herbarium specimen label transcription reimagined with large language models},
	pages = {e16256},
	number = {12},
	journaltitle = {American Journal of Botany},
	author = {Weaver, William N. and Ruhfel, Brad R. and Lough, Kyle J. and Smith, Stephen A.},
	urldate = {2025-06-13},
	date = {2023},
	langid = {english},
	keywords = {{AI} automation, {ChatGPT}, Specimen Label Transcription Project, \_automatisation {IA}, \_exemple, \_outils, biodiversity data, curation, digitization, herbarium label transcription, natural history collections, optical character recognition, {texNumeriquePatrimoine}, workflow},
}

@misc{taboada_ontology_2025,
	title = {Ontology Matching with Large Language Models and Prioritized Depth-First Search},
	url = {http://arxiv.org/abs/2501.11441},
	doi = {10.48550/arXiv.2501.11441},
	abstract = {Ontology matching ({OM}) plays a key role in enabling data interoperability and knowledge sharing, but it remains challenging due to the need for large training datasets and limited vocabulary processing in machine learning approaches. Recently, methods based on Large Language Model ({LLMs}) have shown great promise in {OM}, particularly through the use of a retrieve-then-prompt pipeline. In this approach, relevant target entities are first retrieved and then used to prompt the {LLM} to predict the final matches. Despite their potential, these systems still present limited performance and high computational overhead. To address these issues, we introduce {MILA}, a novel approach that embeds a retrieve-identify-prompt pipeline within a prioritized depth-first search ({PDFS}) strategy. This approach efficiently identifies a large number of semantic correspondences with high accuracy, limiting {LLM} requests to only the most borderline cases. We evaluated {MILA} using the biomedical challenge proposed in the 2023 and 2024 editions of the Ontology Alignment Evaluation Initiative. Our method achieved the highest F-Measure in four of the five unsupervised tasks, outperforming state-of-the-art {OM} systems by up to 17\%. It also performed better than or comparable to the leading supervised {OM} systems. {MILA} further exhibited task-agnostic performance, remaining stable across all tasks and settings, while significantly reducing {LLM} requests. These findings highlight that high-performance {LLM}-based {OM} can be achieved through a combination of programmed ({PDFS}), learned (embedding vectors), and prompting-based heuristics, without the need of domain-specific heuristics or fine-tuning.},
	number = {{arXiv}:2501.11441},
	publisher = {{arXiv}},
	author = {Taboada, Maria and Martinez, Diego and Arideh, Mohammed and Mosquera, Rosa},
	urldate = {2025-06-13},
	date = {2025-03-27},
	eprinttype = {arxiv},
	eprint = {2501.11441 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, \_automatisation {IA}, \_exemple, \_outils, {texNumeriquePatrimoine}},
}

@misc{chataut_comparative_2024,
	title = {Comparative Study of Domain Driven Terms Extraction Using Large Language Models},
	url = {http://arxiv.org/abs/2404.02330},
	doi = {10.48550/arXiv.2404.02330},
	abstract = {Keywords play a crucial role in bridging the gap between human understanding and machine processing of textual data. They are essential to data enrichment because they form the basis for detailed annotations that provide a more insightful and in-depth view of the underlying data. Keyword/domain driven term extraction is a pivotal task in natural language processing, facilitating information retrieval, document summarization, and content categorization. This review focuses on keyword extraction methods, emphasizing the use of three major Large Language Models({LLMs}): Llama2-7B, {GPT}-3.5, and Falcon-7B. We employed a custom Python package to interface with these {LLMs}, simplifying keyword extraction. Our study, utilizing the Inspec and {PubMed} datasets, evaluates the performance of these models. The Jaccard similarity index was used for assessment, yielding scores of 0.64 (Inspec) and 0.21 ({PubMed}) for {GPT}-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. This paper underlines the role of prompt engineering in {LLMs} for better keyword extraction and discusses the impact of hallucination in {LLMs} on result evaluation. It also sheds light on the challenges in using {LLMs} for keyword extraction, including model complexity, resource demands, and optimization techniques.},
	number = {{arXiv}:2404.02330},
	publisher = {{arXiv}},
	author = {Chataut, Sandeep and Do, Tuyen and Gurung, Bichar Dip Shrestha and Aryal, Shiva and Khanal, Anup and Lushbough, Carol and Gnimpieba, Etienne},
	urldate = {2025-06-13},
	date = {2024-04-02},
	eprinttype = {arxiv},
	eprint = {2404.02330 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, \_automatisation {IA}, \_exemple, \_outils, {texNumeriquePatrimoine}},
}

@inproceedings{bermes_repenser_2025,
	location = {Dijon, France},
	title = {Repenser les collections patrimoniales par le prisme de l'{IA} 2025},
	url = {https://hal.science/hal-05138697},
	abstract = {The {TORNE}-H project explores the integration of {AI} in the documentary and scientific processing of museum collections. Focused on the Henrot collection at the musée des Arts décoratifs ({MAD}), it aims to optimize the inventory, indexing, and promotion of artworks through advanced image analysis techniques. Led by {MAD}, the École nationale des chartes, and the {BnF}, the project seeks to rethink human-machine collaboration and develop reproducible processes for other heritage institutions.},
	booktitle = {Conférence Nationale sur les Applications de l'Intelligence Artificielle},
	author = {Bermès, Emmanuelle and Charpier, Marion},
	urldate = {2025-07-05},
	date = {2025},
	keywords = {Collections patrimoniales, Computer vision, Coopération humain-machine, Heritage collections, Humanmachine cooperation, Museum, Musée, Vision par ordinateur, \_automatisation {IA}, \_theorie, {texNumeriquePatrimoine}},
}

@inproceedings{heberlein_flipside_2019,
	location = {Athènes},
	title = {On the Flipside: Wikidata for Cultural Heritage Metadata through the Example of Numismatic Description},
	abstract = {This paper reports on an ongoing project at Princeton University Library to model numismatic descriptive metadata using {FRBR}-oo and Wikidata. Wikidata’s lack of cardinality constraints makes it unsuitable as a standalone data model for cultural heritage description but leaves it unrivaled as point of convergence for data from different vocabularies and ontologies. Conversely, {FRBR}-oo’s eventbased approach positions it uniquely to model a complete set of data points relating to descriptive objects’ creation, administrative life cycle, and relationships transcending custodial contexts, but faces implementation challenges owing to its complexity. Using the example of numismatic description, we argue that when deployed in conjunction with one another, the descriptive rigor of {FRBR}-oo mapped to Wikidata and serviced using the Wikibase technology form a production-ready platform for {GLAM} descriptive metadata.},
	eventtitle = {Libraries, Archives and Museums in Dialogue. Art Libraries Section in collaboration with the Subject Analysis and Access Section},
	author = {Heberlein, Regine},
	date = {2019-06-28},
	langid = {english},
	keywords = {\_data, \_webSemantique, {texNumeriquePatrimoine}},
}

@inproceedings{cher_taking_2019,
	location = {Athènes},
	title = {Taking on the content discovery challenge: The {NLB} Case Study},
	url = {https://library.ifla.org/id/eprint/2494/},
	shorttitle = {Taking on the content discovery challenge},
	abstract = {This paper discusses four major projects undertaken by the National Library Board ({NLB}) to implement content discovery solutions that enhance discovery and accessibility to digitised archived content such as geo-referenced maps, photographs and audio-visual recordings. This paper falls under the “Libraries, archives and museums in dialogue: Improving access to complementary collections” topic.

In November 2012, {NLB}’s role expanded beyond offering library collections when the National Archives of Singapore became an institution of {NLB}. Besides inheriting a treasure trove of primary research material about Singapore government’s corporate memory, public and private records, its role expanded to include collection, preservation and management of those collections. 

First, {NLB} had to consolidate the vast collections across its libraries and the archives to offer a unified research experience. A cross functional team consisting of content specialists and technologists was formed. The team’s first priority was to harmonise content. 

The Archives uses {ISAD}-G (General International Standard Archival Description) to describe archival records while {NLB} uses Dublin Core standard to describe its library collection. Harmonisation is needed to enable a common search interface that offers normalised search results and relevant facets to refine search results. 

This paper will cover the harmonisation process as well as the user research studies to ensure that the labels speak the users’ language, with words, phrases and concepts that are familiar to the users.

Second, having built a common foundation through the data harmonisation project, {NLB} developed new digital research services. One notable example is Spatial Discovery, a platform that allows researchers to search and discover maps from the libraries and archives. The maps are geo-referenced so that researchers can accurately trace the changing landscapes. Beyond {NLB}, the harmonisation project’s outputs have benefitted other local institutions in the cultural heritage business. The National Heritage Board and National Gallery of Singapore were able to leverage the common standards through knowledge and technology sharing via content partnership.

Third, the paper will discuss the {NLB}’s recent experience in leveraging Linked Data and Machine Learning to improve content discovery and access. A common researcher’s feedback is difficulties in drawing linkages between articles with other content. To address the problem, text analysis was used to surface complementary content relevant to the research topic. A linked data feature was also launched to help researchers see the relationships of entities mentioned in the piece of content. Researchers are now able to quickly find out more about the events, personalities and places mentioned.

Finally, beyond employing technologies for content discovery, {NLB} has also used Machine Learning to aid content description. Entity extraction technology was used to geo-tag one million digitised photographs so that they could be delivered on a map view. If done manually, it would be a massive undertaking. The {NLB} is currently in the midst of building its image recognition model to describe its image-based content. When completed, it would be able to assist staff in building metadata by detecting faces and places within images.},
	eventtitle = {Libraries, Archives and Museums in Dialogue. Art Libraries Section in collaboration with the Subject Analysis and Access Section},
	author = {Cher, Patrick},
	urldate = {2025-07-05},
	date = {2019},
	keywords = {\_data, {texNumeriquePatrimoine}},
}

@inproceedings{liu_review_2025,
	title = {A Review of the Application and Development of Artificial Intelligence Technology in Museums},
	url = {https://www.researchgate.net/publication/390434708_A_Review_of_the_Application_and_Development_of_Artificial_Intelligence_Technology_in_Museums},
	doi = {10.1145/3718491.3718523},
	abstract = {Download Citation {\textbar} On Apr 2, 2025, Jun Liu published A Review of the Application and Development of Artificial Intelligence Technology in Museums {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	eventtitle = {The 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
	booktitle = {{ResearchGate}},
	author = {Liu, Jun},
	urldate = {2025-07-05},
	date = {2025-04-05},
	langid = {english},
	keywords = {\_automatisation {IA}, {texNumeriquePatrimoine}},
}

@inproceedings{levar_wegner_metadata_2019,
	location = {Athènes},
	title = {Metadata Obscura: Refocusing digital collections through the lens of art history},
	url = {https://library.ifla.org/id/eprint/2491/},
	shorttitle = {Metadata Obscura},
	abstract = {Art librarians in academic libraries often rely on generalists in metadata and digital collections departments to accurately describe visual collections. When these partnerships are successful, students and researchers in art disciplines can use their subject training to discover and contextualize visual resources. However, art researchers may experience disruption and disconnection in their research when they encounter visual collections that were digitized without proper attention to disciplinary expectations. This is especially important in academic libraries, whose primary mission is to support students and faculty, and where university users are inherently subject specific in their research. This paper discusses the decisions and workflows implemented to revise a popular digital collection of 19th and 20th-century trade cards held at the Walter Havighurst Special Collections at Miami University. By aligning subject metadata with the methodologies of art history, librarians improved the accessibility and discoverability of these visual materials for art researchers.},
	eventtitle = {Libraries, Archives and Museums in Dialogue. Art Libraries Section in collaboration with the Subject Analysis and Access Section},
	author = {Levar Wegner, Alia and Hilles, Stefanie},
	urldate = {2025-07-05},
	date = {2019},
	keywords = {\_data, {texNumeriquePatrimoine}},
}
